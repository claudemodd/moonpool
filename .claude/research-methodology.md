# Research methodology and standards for Project Moonpool

## Research quality framework

### Source credibility assessment criteria
**Authority evaluation**:
- Does the source have recognised expertise in the domain?
- Are author credentials and institutional affiliations verifiable?
- Is there evidence of peer review or editorial oversight?

**Currency assessment**:
- Is the information recent and regularly updated?
- Are publication dates clearly documented?
- Does the source reflect current market conditions?

**Accuracy verification**:
- Can claims be verified through multiple independent sources?
- Are statistics and data points cross-referenced?
- Is methodology for data collection documented?

**Purpose and bias evaluation**:
- Is the source objective or does it have commercial bias?
- Are potential conflicts of interest disclosed?
- Does the source provide comprehensive or selective information?

### Reputable source categories
**Academic sources**:
- Peer-reviewed journals and research institutions
- University publications and academic databases
- Government research bodies and statistical agencies

**Industry authorities**:
- Standards bodies (ISO, NIST, W3C)
- Recognised industry analysts (Gartner, Forrester, CB Insights)
- Professional associations and regulatory bodies

**Financial institutions**:
- Central banks and government financial agencies
- Official company documentation and verified financial reports
- Published case studies with disclosed methodologies

**Media sources**:
- Established financial and technology publications
- Editorial standards and fact-checking processes
- Clear distinction between news and opinion content

## Source documentation standards

### Mandatory documentation requirements
**Complete URL verification**:
- Test every URL for accessibility before inclusion
- Document URL verification date
- Provide alternative access methods if primary link fails

**Bibliographic completeness**:
- Author name and credentials
- Publication title and organisation
- Publication date and last updated date
- Complete URL and access date

**Inline citation format**:
```
"According to [Author Name, Organisation] (publication date), [specific claim]." [Source: Full URL]
```

**Sources section format**:
```
## Sources
1. [Author Name]. "[Full Title]." [Organisation/Publication]. [Date]. [Complete URL]
2. [Continue numbering for all sources...]
```

### Source validation workflow
**During research collection**:
1. Capture source details immediately when finding information
2. Record full URL, author, publication date, organisation
3. Test URL accessibility before proceeding with content analysis
4. Note potential biases or limitations of each source
5. Maintain source bibliography throughout research process

**During analysis and writing**:
1. Attribute every claim immediately with inline citations
2. Cross-reference statistics and key findings across multiple sources
3. Document methodology for finding and validating sources
4. Identify conflicting information and explain discrepancies
5. Flag areas needing additional sources if claims lack sufficient support

**Pre-publication verification**:
1. Verify every URL works and content remains accessible
2. Confirm minimum source requirements met (3-5 sources per key finding)
3. Check author credentials and publication credibility
4. Assess balance of recent and foundational sources
5. Document validation methodology in research reports

## Research process standards

### Research planning
**Objective definition**:
- Clear research questions and scope boundaries
- Success criteria and deliverable specifications
- Timeline and resource allocation
- Stakeholder requirements and constraints

**Search strategy development**:
- Keyword identification and search term variations
- Source selection criteria and prioritisation
- Search methodology documentation
- Quality gates and review checkpoints

### Information gathering
**Search execution**:
- Systematic approach across identified source categories
- Documentation of search terms and databases used
- Record of sources considered but not included
- Note of information gaps or unavailable data

**Content evaluation**:
- Apply credibility assessment framework consistently
- Cross-reference claims across multiple sources
- Document conflicting information and potential explanations
- Assess completeness and identify research limitations

### Analysis and synthesis
**Data validation**:
- Verify statistics and quantitative claims
- Check calculation accuracy and unit consistency
- Assess sample sizes and methodological soundness
- Document assumptions and limitations

**Insight development**:
- Identify patterns and trends across sources
- Develop actionable recommendations based on evidence
- Distinguish between correlation and causation
- Acknowledge uncertainty and confidence levels

## Research output standards

### Mandatory report sections
**Executive summary**:
- Key findings and implications
- Strategic recommendations
- Critical uncertainties and limitations

**Research methodology**:
- Search approach and keywords used
- Source selection criteria and validation steps
- Limitations and potential biases
- Currency of data and analysis

**Analysis content**:
- Detailed findings with inline source attribution
- Cross-referenced claims with multiple sources
- Clear distinction between facts and interpretation
- Identified conflicts and unresolved questions

**Sources documentation**:
- Complete bibliography with working URLs
- Source accessibility verification date
- Assessment of source credibility and limitations
- Documentation of excluded sources and rationale

### Quality control checklist
**Source verification**:
- [ ] Every statistical claim has a source with working URL
- [ ] Every quote or paraphrase includes author and publication details
- [ ] Sources section includes complete bibliographic information
- [ ] All URLs tested and accessible within 24 hours of publication
- [ ] Minimum 3-5 sources per major finding
- [ ] Both recent and foundational sources included
- [ ] Author credentials and publication credibility verified
- [ ] Potential biases identified and disclosed

**Content quality**:
- [ ] Clear research objectives achieved
- [ ] Analysis distinguishes facts from interpretation
- [ ] Recommendations actionable and evidence-based
- [ ] Limitations and uncertainties acknowledged
- [ ] British English spelling and sentence case formatting
- [ ] Writing clear and accessible to target audience

### Knowledge persistence requirements
**Research artifact creation**:
- Save complete report to research directory using proper naming convention
- Format: `[research-type]-[topic]-[YYYY].md`
- Include all mandatory sections and source documentation
- Verify file accessibility by team members

**Knowledge extraction workflow**:
1. **Market insights** → Update `.claude/market-insights.md`
2. **Competitive intelligence** → Update `.claude/competitive-landscape.md`
3. **Technical findings** → Update appropriate domain files in `.claude/`
4. **Methodology improvements** → Update `.claude/research-methodology.md`
5. **Project implications** → Update `./CLAUDE.md` with strategic insights

**Cross-agent accessibility**:
- Extract actionable insights for team consumption
- Update knowledge files with new market intelligence
- Ensure findings inform architectural and technical decisions
- Document implications for product strategy and development

## Specific research domains

### Market analysis standards
**Competitive landscape research**:
- Minimum 10-15 competitors across relevant categories
- Funding, valuation, and traction metrics where available
- Feature analysis and gap identification
- Strategic positioning and differentiation assessment

**Market sizing and trends**:
- Multiple data sources for market size validation
- Clear distinction between total addressable and serviceable markets
- Trend analysis with supporting quantitative evidence
- Regional market characteristics and variations

### Technical research standards
**Technology evaluation**:
- Architecture patterns and implementation approaches
- Performance benchmarks and scalability considerations
- Security and privacy implications
- Integration requirements and ecosystem compatibility

**Standards and compliance research**:
- Regulatory requirements and compliance frameworks
- Industry standards and best practices
- Privacy regulations and data protection requirements
- Accessibility and inclusion standards

### User research integration
**Market validation**:
- User needs and pain point identification
- Demographic analysis and segmentation
- Behavioural patterns and usage scenarios
- Willingness to pay and pricing sensitivity

**Competitive user experience analysis**:
- Feature usability and user satisfaction
- User journey mapping and friction points
- Community feedback and review analysis
- Support and onboarding effectiveness

## Continuous improvement
**Methodology refinement**:
- Regular review and update of research standards
- Incorporation of lessons learned from completed research
- Adaptation to new source types and research domains
- Integration of feedback from research consumers

**Tool and process optimisation**:
- Evaluation of research tools and database access
- Automation of routine verification tasks
- Template development for common research types
- Knowledge management system enhancement

## Last updated
August 2025 - Developed for Project Moonpool research quality assurance